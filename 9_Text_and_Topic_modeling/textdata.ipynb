{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (confusion_matrix,precision_score,recall_score,f1_score,\n",
    "    roc_curve,roc_auc_score,precision_recall_curve,accuracy_score,classification_report)\n",
    "from sklearn.decomposition import LatentDirichletAllocation,PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: preprocessing and vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a dataset containing movie reviews from the *Internet Movie Database*. For this, the data first needs to be downloaded from <a href=\"http://ai.stanford.edu/~amaas/data/sentiment/\"> here </a>. Note: this is about 220 Mb.  After uncompressing, the data is contained in a directory `aclImdb` with sub-directories `train` and `test`. In the following, replace the piece of the path that leads to the directory in which you have unpacked the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train=load_files('/Users/hecter/Downloads/aclImdb/train/',categories=['neg','pos'])\n",
    "reviews_test = load_files('/Users/hecter/Downloads/aclImdb/test/',categories=['neg','pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n",
      "b'Everyone plays their part pretty well in this \"little nice movie\". Belushi gets the chance to live part of his life differently, but ends up realizing that what he had was going to be just as good or maybe even better. The movie shows us that we ought to take advantage of the opportunities we have, not the ones we do not or cannot have. If U can get this movie on video for around $10, it\\xc2\\xb4d be an investment!'\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(reviews_train.target_names)\n",
    "revidx = 2\n",
    "print(reviews_train.data[revidx])\n",
    "print(reviews_train.target[revidx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a dictionary (using training data only!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=CountVectorizer(min_df=0.0005, max_df=0.5).fit(reviews_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary contains 15862 entries\n",
      "The index of the word 'charming' in the dictionary is 2466\n",
      "The word at index 708 is 'an'\n"
     ]
    }
   ],
   "source": [
    "print(\"The dictionary contains {} entries\".format(len(dictionary.vocabulary_)))\n",
    "wrd='charming'\n",
    "\n",
    "print(\"The index of the word '{}' in the dictionary is {}\".format(wrd,dictionary.vocabulary_[wrd]))\n",
    "widx=708\n",
    "print(\"The word at index {} is '{}'\".format(widx,dictionary.get_feature_names_out()[widx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the underlying preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['everyone', 'plays', 'their', 'part', 'pretty', 'well', 'in', 'this', 'little', 'nice', 'movie', 'belushi', 'gets', 'the', 'chance', 'to', 'live', 'part', 'of', 'his', 'life', 'differently', 'but', 'ends', 'up', 'realizing', 'that', 'what', 'he', 'had', 'was', 'going', 'to', 'be', 'just', 'as', 'good', 'or', 'maybe', 'even', 'better', 'the', 'movie', 'shows', 'us', 'that', 'we', 'ought', 'to', 'take', 'advantage', 'of', 'the', 'opportunities', 'we', 'have', 'not', 'the', 'ones', 'we', 'do', 'not', 'or', 'cannot', 'have', 'if', 'can', 'get', 'this', 'movie', 'on', 'video', 'for', 'around', '10', 'it', 'be', 'an', 'investment']\n"
     ]
    }
   ],
   "source": [
    "analyze = dictionary.build_analyzer()\n",
    "print(analyze(reviews_train.data[revidx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary construction with `CountVectorizer` does not include stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horrendous' 'horrendously' 'horrible' 'horribly' 'horrid']\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.get_feature_names_out()[6951:6956])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specialized tools for tokenization, stemming etc. are provided by the 'nltk' package. We leave this out for now, and go ahead with transforming the data into tf feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of 'reviews_train_tf' is <class 'scipy.sparse._csr.csr_matrix'> with 25000 rows and 15862 columns\n"
     ]
    }
   ],
   "source": [
    "reviews_train_tf=dictionary.transform(reviews_train.data)\n",
    "\n",
    "print(\"The type of 'reviews_train_tf' is {} with {} rows \\\n",
    "and {} columns\".format(type(reviews_train_tf),reviews_train_tf.shape[0],reviews_train_tf.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sparse matrix structure becomes visible, when we print the first 1000 entries of the row for the review at index `revidx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t1\n",
      "  (0, 446)\t1\n",
      "  (0, 708)\t1\n",
      "  (0, 951)\t1\n"
     ]
    }
   ],
   "source": [
    "print(reviews_train_tf[revidx,0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing 0s are still 'there':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(reviews_train_tf[revidx,405])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also construct a tf-idf representation of the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 951)\t0.11428633904228334\n",
      "  (0, 708)\t0.0627784554562377\n",
      "  (0, 446)\t0.22416564513504342\n",
      "  (0, 7)\t0.10966712876468465\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer_train=TfidfTransformer().fit(reviews_train_tf)\n",
    "reviews_train_tfidf=tfidf_transformer_train.transform(reviews_train_tf)\n",
    "print(reviews_train_tfidf[revidx,0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the feature vector for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning a Naive Bayes model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb=MultinomialNB().fit(reviews_train_tf,reviews_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and transforming the test data. The dictionary used for the test data is the one constructed from the training data! Also the transformation with the idf values is done using the TfidfTransformer constructed from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test_tf=dictionary.transform(reviews_test.data)\n",
    "reviews_test_tfidf = tfidf_transformer_train.transform(reviews_test_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the learned model to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: \n",
      " 0.82968\n",
      "\n",
      "Accuracy on train: \n",
      " 0.87324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_train=mnb.predict(reviews_train_tf)\n",
    "predictions_test=mnb.predict(reviews_test_tf)\n",
    "\n",
    "print(\"Accuracy on test: \\n {}\\n\".format(accuracy_score(reviews_test.target,predictions_test)))\n",
    "print(\"Accuracy on train: \\n {}\\n\".format(accuracy_score(reviews_train.target,predictions_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find out about what words are most indicative of postive/negative reviews, by looking at the parameters of the model.\n",
    "\n",
    "The attribute `feature_log_prob_` returns the log probabilities of the different features (words) under the two classes. By taking the difference for the two classes, we get a measure for how much a word discriminates between the two classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_diff=mnb.feature_log_prob_[0,:]-mnb.feature_log_prob_[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `np.argsort` to obtain the indices of the values in log_prob_diff in increasing order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4636   814  4116  6443  6210 15802 10285 15226  1626  6127  1851  3723\n",
      "  6576 10163  9993 14676 12154  1200  8898  3610  1609  7923 14593  6806\n",
      "  9862 12647  8048 10302  6439 15122]\n"
     ]
    }
   ],
   "source": [
    "sorted_idxs=np.argsort(log_prob_diff)\n",
    "print(sorted_idxs[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and retrieve the words corresponding to these indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 words most discriminating for positive reviews are:\n",
      "\n",
      "edie\n",
      "antwone\n",
      "din\n",
      "gunga\n",
      "goldsworthy\n",
      "yokai\n",
      "paulie\n",
      "visconti\n",
      "blandings\n",
      "gino\n",
      "brashear\n",
      "deathtrap\n",
      "harilal\n",
      "panahi\n",
      "ossessione\n",
      "tsui\n",
      "sabu\n",
      "aweigh\n",
      "mcintire\n",
      "daisies\n",
      "\n",
      "\n",
      "The 20 words most discriminating for negative reviews are:\n",
      "\n",
      "weisz\n",
      "wayans\n",
      "dyer\n",
      "rosanna\n",
      "dahmer\n",
      "dunaway\n",
      "savini\n",
      "beowulf\n",
      "seagal\n",
      "thunderbirds\n",
      "manos\n",
      "shaq\n",
      "btk\n",
      "saif\n",
      "kareena\n",
      "hobgoblins\n",
      "tashan\n",
      "slater\n",
      "uwe\n",
      "boll\n"
     ]
    }
   ],
   "source": [
    "numfeats=20\n",
    "print(\"The {} words most discriminating for positive reviews are:\\n\".format(numfeats))\n",
    "for i in sorted_idxs[0:numfeats]:\n",
    "    print(dictionary.get_feature_names_out()[i])\n",
    "print(\"\\n\")    \n",
    "print(\"The {} words most discriminating for negative reviews are:\\n\".format(numfeats))\n",
    "for i in sorted_idxs[len(sorted_idxs)-numfeats:len(sorted_idxs)]:\n",
    "    print(dictionary.get_feature_names_out()[i])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that we are overfitting due to very rare words. We can inspect instead words that are a little bit away from the extreme ends of the sorted log_prob_diff vector: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with 'positive rank' between 500 and 520:\n",
      "\n",
      "alienate\n",
      "opposites\n",
      "undercurrent\n",
      "companionship\n",
      "moriarty\n",
      "swordplay\n",
      "demme\n",
      "conductor\n",
      "amicus\n",
      "sergeants\n",
      "trading\n",
      "seamlessly\n",
      "cheryl\n",
      "corinne\n",
      "brilliantly\n",
      "iran\n",
      "shanghai\n",
      "mesmerizing\n",
      "favorites\n",
      "sullivan\n",
      "\n",
      "\n",
      "Words with 'positive rank' between 15342 and 15362:\n",
      "\n",
      "whack\n",
      "humourless\n",
      "sasquatch\n",
      "winston\n",
      "aimlessly\n",
      "whopping\n",
      "plastic\n",
      "horribly\n",
      "horrendous\n",
      "rambo\n",
      "lackluster\n",
      "hulk\n",
      "rehash\n",
      "dafoe\n",
      "bother\n",
      "simpson\n",
      "rubber\n",
      "cringing\n",
      "costs\n",
      "dumb\n"
     ]
    }
   ],
   "source": [
    "numfeats=20\n",
    "offset = 500\n",
    "print(\"Words with 'positive rank' between {} and {}:\\n\".format(offset,offset+numfeats))\n",
    "for i in sorted_idxs[offset:offset+numfeats]:\n",
    "    print(dictionary.get_feature_names_out()[i])\n",
    "print(\"\\n\")    \n",
    "print(\"Words with 'positive rank' between {} and {}:\\n\".format(len(sorted_idxs)-numfeats-offset,len(sorted_idxs)-offset))\n",
    "for i in sorted_idxs[len(sorted_idxs)-numfeats-offset:len(sorted_idxs)-offset]:\n",
    "    print(dictionary.get_feature_names_out()[i])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try a neural network classifier on the tf-idf transformed data next. We use a fairly strong regularization with `alpha=0.5` to compensate for the strong overfitting opportunities in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hecter/miniconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(alpha=0.5).fit(reviews_train_tfidf, reviews_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is runnig (~ 5 minutes ...?), we can take a little break!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train=mlp.predict(reviews_train_tfidf)\n",
    "predictions_test=mlp.predict(reviews_test_tfidf)\n",
    "\n",
    "\n",
    "print(\"Accuracy on test: \\n {}\\n\".format(accuracy_score(reviews_test.target,predictions_test)))\n",
    "print(\"Accuracy on train: \\n {}\\n\".format(accuracy_score(reviews_train.target,predictions_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the reviews that are evaluated as most positive (negative) by the MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_positive=np.argsort( mlp.predict_proba(reviews_test_tfidf)[:,0] )\n",
    "print(most_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numrevs = 3\n",
    "\n",
    "print(\"The {} reviews ranked as most positive are:\\n\".format(numrevs))\n",
    "for i in most_positive[0:numrevs]:\n",
    "    print(reviews_test.data[i])\n",
    "    print(\"\\n\\n\")\n",
    " \n",
    "print(\"The {} reviews ranked as most negative are:\\n\".format(numrevs))\n",
    "for i in most_positive[len(most_positive)-numrevs:len(most_positive)]:\n",
    "    print(reviews_test.data[i])\n",
    "    print(\"\\n\\n\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opgaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: install the 'nltk' package https://www.nltk.org/. Now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hecter/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt') #Provides tokenization rules for English\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should work. The package provides customizable methods for tokenization and stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed: \n",
      " b'everyon play their part pretti well in thi `` littl nice movi '' . belushi get the chanc to live part of hi life differ , but end up realiz that what he had wa go to be just as good or mayb even better . the movi show us that we ought to take advantag of the opportun we have , not the one we do not or can not have . if u can get thi movi on video for around $ 10 , it\\xc2\\xb4d be an invest ! '\n"
     ]
    }
   ],
   "source": [
    "revidx = 2\n",
    "\n",
    "#print(\"Tokenized: \\n {}\".format(tokens))\n",
    "ps=PorterStemmer()\n",
    "def stem(review):\n",
    "    tokens=word_tokenize(str(review))\n",
    "    stemmed = []\n",
    "    for t in tokens:\n",
    "        stemmed.append(ps.stem(t))\n",
    "    \n",
    "    stemmed = \" \".join(stemmed)\n",
    "    \n",
    "    return stemmed\n",
    "\n",
    "stemmed = stem(reviews_train.data[revidx]) \n",
    "\n",
    "print(\"Stemmed: \\n {}\".format(stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Everyone plays their part pretty well in this \"little nice movie\". Belushi gets the chance to live part of his life differently, but ends up realizing that what he had was going to be just as good or maybe even better. The movie shows us that we ought to take advantage of the opportunities we have, not the ones we do not or cannot have. If U can get this movie on video for around $10, it\\xc2\\xb4d be an investment!'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_train.data[revidx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise continued**: Create a new (smaller) dictionary from stemmed versions of the reviews. How has the size of the dictionary changed, when you use the same min_df, max_df parameters in the CountVectorizer as before? Redo the NaiveBayes and MLP training with the modified data. Does accuracy improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_corpus = []\n",
    "for i in range(len(reviews_train.data)):\n",
    "    stemmed_corpus.append(stem(reviews_train.data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=CountVectorizer(min_df=0.0005, max_df=0.5).fit(stemmed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('00', 0),\n",
       " ('000', 1),\n",
       " ('007', 2),\n",
       " ('01', 3),\n",
       " ('02', 4),\n",
       " ('05', 5),\n",
       " ('06', 6),\n",
       " ('10', 7),\n",
       " ('100', 8),\n",
       " ('1000', 9)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dictionary.vocabulary_.items(), key=lambda x: x[1], reverse=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary contains 11878 entries\n",
      "The index of the word 'your' in the dictionary is 11828\n",
      "The word at index 5 is '05'\n"
     ]
    }
   ],
   "source": [
    "print(\"The dictionary contains {} entries\".format(len(dictionary.vocabulary_)))\n",
    "wrd='your'\n",
    "\n",
    "print(\"The index of the word '{}' in the dictionary is {}\".format(wrd,dictionary.vocabulary_[wrd]))\n",
    "widx=5\n",
    "print(\"The word at index {} is '{}'\".format(widx,dictionary.get_feature_names_out()[widx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 11878 features, but TfidfTransformer is expecting 15862 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hecter/Library/CloudStorage/OneDrive-Personligt/7_semester/Advanced Statistical Machine Learning/Exercises/Lecture_12/textdata.ipynb Cell 55\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hecter/Library/CloudStorage/OneDrive-Personligt/7_semester/Advanced%20Statistical%20Machine%20Learning/Exercises/Lecture_12/textdata.ipynb#Y164sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m reviews_test_tf\u001b[39m=\u001b[39mdictionary\u001b[39m.\u001b[39mtransform(reviews_test\u001b[39m.\u001b[39mdata)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hecter/Library/CloudStorage/OneDrive-Personligt/7_semester/Advanced%20Statistical%20Machine%20Learning/Exercises/Lecture_12/textdata.ipynb#Y164sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m reviews_test_tfidf \u001b[39m=\u001b[39m tfidf_transformer_train\u001b[39m.\u001b[39;49mtransform(reviews_test_tf)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:1710\u001b[0m, in \u001b[0;36mTfidfTransformer.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1694\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Transform a count matrix to a tf or tf-idf representation.\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \n\u001b[1;32m   1696\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1708\u001b[0m \u001b[39m        Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[1;32m   1709\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1710\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1711\u001b[0m         X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES, copy\u001b[39m=\u001b[39;49mcopy, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1712\u001b[0m     )\n\u001b[1;32m   1713\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39missparse(X):\n\u001b[1;32m   1714\u001b[0m         X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 626\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    628\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/sklearn/base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 415\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 11878 features, but TfidfTransformer is expecting 15862 features as input."
     ]
    }
   ],
   "source": [
    "reviews_test_tf=dictionary.transform(reviews_test.data)\n",
    "reviews_test_tfidf = tfidf_transformer_train.transform(reviews_test_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import a pre-computed 100-dimensional embedding of a vocabulary of 400.000 words. The data can be imported from <a href=\"http://nlp.stanford.edu/data/glove.6B.zip\">here</a> from the <a href=\"https://nlp.stanford.edu/projects/glove/\">Glove homepage</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code copied from https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python\n",
    "\n",
    "def loadGloveModel(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(File,'r')\n",
    "    gloveModel = {}\n",
    "    for line in f:\n",
    "        splitLines = line.split()\n",
    "        word = splitLines[0]\n",
    "        wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
    "        gloveModel[word] = wordEmbedding\n",
    "    print(len(gloveModel),\" words loaded!\")\n",
    "    return gloveModel\n",
    "\n",
    "gl=loadGloveModel('/home/jaeger/Data/Glove/glove.6B.100d.txt')\n",
    "\n",
    "print(\"The type of the loaded model is {} \\n \".format(type(gl)))\n",
    "\n",
    "print(\"The embedding vector of 'university' is \\n {}\".format(gl['university']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming back to our movie reviews, we create another dictionary from the reviews in the training set. We now set limits that terms included in the dictionary should appear in at least 5% and at most 80% of reviews. These are rather narrow bounds, which are set under the assumption that typical words expressing sentiments will fall into these bounds, while stop words and very many more specific words will be excluded. As it turns out, we create a rather small vocabulary in this manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_small=CountVectorizer(min_df=0.05, max_df=0.8).fit(reviews_train.data)\n",
    "\n",
    "ld=len(dictionary_small.vocabulary_)\n",
    "print(\"Created a dictionary with {} tokens: \\n\".format(ld)) \n",
    "for i in range(ld):\n",
    "    print(dictionary_small.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new tf feature vectors for the smaller dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_tf=dictionary_small.transform(reviews_train.data)\n",
    "reviews_test_tf=dictionary_small.transform(reviews_test.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need the Glove vector representations of the words in our dictionary. We therefore extract from our 400.000 word original Glove dictionary the relevant ones, and collect them in a matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_glove=np.zeros((ld,100))\n",
    "for i in range(ld):\n",
    "    dict_glove[i,:]=gl[dictionary_small.get_feature_names()[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now represent each review by the average of the Glove word vectors of the words in the review (only taking into account those that are in our dictionary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_glove= np.matmul(reviews_train_tf.todense(),dict_glove)\n",
    "for r in range(25000):\n",
    "    reviews_train_glove[r,:]*=(1/np.sum(reviews_train_tf[r,:]))\n",
    "\n",
    "reviews_test_glove= np.matmul(reviews_test_tf.todense(),dict_glove)\n",
    "for r in range(25000):\n",
    "    reviews_test_glove[r,:]*=(1/np.sum(reviews_test_tf[r,:]))    \n",
    "    \n",
    "    \n",
    "print(\"glove feature matrix for training reviews has dimensions {}\".format(reviews_train_glove.shape))\n",
    "print(\"glove feature matrix for testing reviews has dimensions {}\".format(reviews_test_glove.shape))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train classifiers for predicting the sentiment of a review from either the term-frequency features, or the GLove average embedding vectors. Remember that the tf-vectors are now over a smaller dictionary, so the accuracy results we get can be expected to be lower than in Part 1. The true class labels are retrieved by `reviews_train.target` and `reviews_test.target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyer = MLPClassifier((10))\n",
    "#classifyer =  LogisticRegression(solver='lbfgs')\n",
    "train={}\n",
    "train[\"tf\"]=reviews_train_tf\n",
    "train[\"glove\"]=reviews_train_glove\n",
    "test={}\n",
    "test[\"tf\"]=reviews_test_tf\n",
    "test[\"glove\"]=reviews_test_glove\n",
    "\n",
    "for features in (\"tf\",\"glove\"):\n",
    "    print(\"Training with \" + features + \"  features \\n\")\n",
    "    classifyer.fit(train[features],reviews_train.target)\n",
    "    pred_train=classifyer.predict(train[features])\n",
    "    pred_test=classifyer.predict(test[features])\n",
    "    print(\"Evaluation on training data: \\n\")\n",
    "    print(\"Confusion matrix: \\n {}\".format(confusion_matrix(pred_train,reviews_train.target)))\n",
    "    print(\"Accuracy: \\n {} \\n\".format(accuracy_score(pred_train,reviews_train.target)))\n",
    "    print(\"Evaluation on test data: \\n\")\n",
    "    print(\"Confusion matrix: \\n {}\".format(confusion_matrix(pred_test,reviews_test.target)))\n",
    "    print(\"Accuracy: \\n {}\\n\\n\".format(accuracy_score(pred_test,reviews_test.target)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent on the random initializations, some learning runs here may end with an warning message that the optimization has not converged after the maximum number of iterations. In that case one can re-run, increase the maximum number of iterations, or live with the results that one has obtained from the not fully converged runs...\n",
    "\n",
    "In these initial experiments, we are likely to see results where the Glove features lead to a slightly lower accuracy on the test data than the TF features. One could explore this further in many different dimensions: modify the underlying vocabulary, create more sophisticated Glove-based features than simple averages, consider other classification models, ...\n",
    "\n",
    "Finally, we can visualize the Glove embeddings of the words in our dictionary by plotting a 2-dimensional projection computed by principal component analysis (PCA): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=2)\n",
    "glove_pca=pca.fit_transform(dict_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "plt.scatter(glove_pca[:,0],glove_pca[:,1],)\n",
    "\n",
    "for i in range(ld):\n",
    "    plt.annotate(dictionary_small.get_feature_names()[i],(glove_pca[i,0],glove_pca[i,1]),fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This picture can partly explain why our sentiment analysis task remains hard with Glove features:  relevant descriptive adjectives 'stupid', 'awful', 'wonderful', 'funny', 'boring', ... are clustered in the same area of the latent space. It would be more helpful, if the positive adjectives were well separated from the negative adjectives (bearing in mind, that this 2-d projection does not tell the whole story!). \n",
    "\n",
    "An interesting detail can be seen on the top of the plot: from this embedding, we would obtain for the analogical query <i>'films' is to 'film' what ??? is to 'movie'</i> the answer ???='movies'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since LDA requires some rather time-consuming computations, we again create a dictionary with a suitable size ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=CountVectorizer(min_df=0.01, max_df=0.15).fit(reviews_train.data)\n",
    "print(\"The dictionary contains {} entries\".format(len(dictionary.vocabulary_)))\n",
    "reviews_train_tf=dictionary.transform(reviews_train.data)\n",
    "reviews_train_tfidf=TfidfTransformer().fit_transform(reviews_train_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit an LDA model with `ntopics` latent topics. The LDA learner has a parameter `max_iter` that determines how many iterations over the whole dataset are performed. A *perplexity* score measures how well the learned model explains/fits the data. When time permits, one can see how the perplexity score improves when one allows more iterations in the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntopics=20\n",
    "\n",
    "#maxiters = np.array([5,10])\n",
    "maxiters = 5\n",
    "\n",
    "for m in range(maxiters):\n",
    "    start=time.time()\n",
    "    lda = LatentDirichletAllocation(n_components=ntopics,learning_method='online',max_iter=m).fit(reviews_train_tf)\n",
    "    end=time.time()\n",
    "    print(\"Time: {}s\".format(end-start))\n",
    "    print(\"Iterations performed: {}\".format(lda.n_iter_))\n",
    "    print(\"Perplexity score: {}\".format(lda.perplexity(reviews_train_vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `components_` contains the word probabilities for the latent topics (not strictly probabilities, because they do not sum to 1 over all words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda.components_.shape)\n",
    "comp=0\n",
    "f=30\n",
    "print(\"The first {} words have the following 'probabilities' in component {}:\\n {}\\n\"\\\n",
    "      .format(f,comp,lda.components_[comp,0:f]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next investigate which words have the highest probabilities under the different topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widx_ranks=np.argsort(lda.components_,axis=1)\n",
    "\n",
    "numwords=20\n",
    "for i in np.arange(ntopics):\n",
    "    print(\"Topic {}\\n\".format(i))\n",
    "    for j in np.arange(numwords):\n",
    "        print(dictionary.get_feature_names()[widx_ranks[i,len(dictionary.vocabulary_)-j-1]])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we investigate the topic distributions assigned to the different reviews. These have first to be computed using the `transform` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicvecs = lda.transform(reviews_train_tf)\n",
    "\n",
    "print(topicvecs.shape)\n",
    "print(topicvecs[0:3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can look which reviews are most strongly connected to any specific topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "toprevs_by_topic=np.argsort(topicvecs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index of the topic we want to investigate\n",
    "topicno=7\n",
    "# The number of reviews most highly associated with the topic that we want to see\n",
    "norevs=4\n",
    "\n",
    "l=len(toprevs_by_topic)-1\n",
    "\n",
    "for i in np.arange(norevs):    \n",
    "    print(reviews_train.data[toprevs_by_topic[l-i,topicno]])\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Try different classifiers (MLP, SVM) for classifying the reviews based on their topic vectors. <b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise (self study) \n",
    "Fix a dimensionality d for vector representations, e.g. d=50, d=100, d=1000. Construct different representations of the reviews as d-dimensional vectors: <b>\n",
    "    \n",
    "<ul>\n",
    "    <li>tf-idf vectors for a dictionary of size d</li>\n",
    "     <li>mean word embedding vectors from d-dimensional word vectors (the GloVe homepage provides embeddings of different dimensions)</li>\n",
    "    <li>LDA topic vectors for d topics </li>\n",
    " </ul>\n",
    "    \n",
    "Train and evaluate different classifiers on these different representations. What are the relevant tuning possibilities you can use to optimize the performance of each type of representation? Which approach gives you the best performance for the given \"budget\" of d dimensions for representation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files('/Users/hecter/Downloads/aclImdb/train/',categories=['neg','pos'])\n",
    "reviews_test = load_files('/Users/hecter/Downloads/aclImdb/test/',categories=['neg','pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF vectors**\n",
    "* $TF(d)$: D-dimensional integer-vector with $TF(d)[i]$ = number of occurrences of the $i$â€™th dictionary term in $d$.\n",
    "* IDF: For $i$'th word in dictionary relative to corpus $c$: $idf(i,c)=\\text{log } \\dfrac{N}{N_i}$ ;$N$ is number of documents in corpus and $N_i$ is number of documents in corpus containing $i$.\n",
    "* TF-IDF: Multiply tf-values with idf scores:\n",
    "$$\n",
    "tfidf(d)[i] = tf(d)[i]idf(i,c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate TF-IDF scores for all words in the corpus and sort them in descending order based on TF-IDF score.\n",
    "2. Choose either the top 50, 100 or 1000 words and create the TF-IDF vector for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes accuracy - num features 10: 0.58412\n",
      "Logistic regression accuracy - num features 10: 0.6\n",
      "Naive bayes accuracy - num features 50: 0.61704\n",
      "Logistic regression accuracy - num features 50: 0.64576\n",
      "Naive bayes accuracy - num features 1000: 0.83288\n",
      "Logistic regression accuracy - num features 1000: 0.86372\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "for max_features in (10,50,1000):\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "    tfidf_vectors = vectorizer.fit_transform(reviews_train.data)\n",
    "    tfidf_vectors_test = vectorizer.transform(reviews_test.data)\n",
    "\n",
    "    # Train and evaluate naive bayes classifier\n",
    "    nb_model = MultinomialNB().fit(tfidf_vectors, reviews_train.target)\n",
    "    predictions = nb_model.predict(tfidf_vectors_test)\n",
    "    print(f\"Naive bayes accuracy - num features {max_features}:\", accuracy_score(reviews_test.target, predictions))\n",
    "    \n",
    "    # Train and evaluate logistic regression model\n",
    "    lr_model = LogisticRegression(solver='lbfgs').fit(tfidf_vectors, reviews_train.target)\n",
    "    predictions = lr_model.predict(tfidf_vectors_test)\n",
    "    print(f\"Logistic regression accuracy - num features {max_features}:\", accuracy_score(reviews_test.target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relevant tuning possibilities**\n",
    "* Additional preprocessing:\n",
    "    * Stemming\n",
    "    * Stop word removal\n",
    "    * DF constraint - similar effect to stop word removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first try constraints on document frequency excluding some words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes accuracy - num features 1000: 0.67236\n",
      "Logistic regression accuracy - num features 1000: 0.69112\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=50, min_df=10, max_df=0.5)\n",
    "tfidf_vectors = vectorizer.fit_transform(reviews_train.data)\n",
    "tfidf_vectors_test = vectorizer.transform(reviews_test.data)\n",
    "\n",
    "# Train and evaluate naive bayes classifier\n",
    "nb_model = MultinomialNB().fit(tfidf_vectors, reviews_train.target)\n",
    "predictions = nb_model.predict(tfidf_vectors_test)\n",
    "print(f\"Naive bayes accuracy - num features {max_features}:\", accuracy_score(reviews_test.target, predictions))\n",
    "\n",
    "# Train and evaluate logistic regression model\n",
    "lr_model = LogisticRegression(solver='lbfgs').fit(tfidf_vectors, reviews_train.target)\n",
    "predictions = lr_model.predict(tfidf_vectors_test)\n",
    "print(f\"Logistic regression accuracy - num features {max_features}:\", accuracy_score(reviews_test.target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition of stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive bayes accuracy - num features 1000: 0.69636\n",
      "Logistic regression accuracy - num features 1000: 0.70356\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=50, min_df=10, max_df=0.5, stop_words='english')\n",
    "tfidf_vectors = vectorizer.fit_transform(reviews_train.data)\n",
    "tfidf_vectors_test = vectorizer.transform(reviews_test.data)\n",
    "\n",
    "# Train and evaluate naive bayes classifier\n",
    "nb_model = MultinomialNB().fit(tfidf_vectors, reviews_train.target)\n",
    "predictions = nb_model.predict(tfidf_vectors_test)\n",
    "print(f\"Naive bayes accuracy - num features {max_features}:\", accuracy_score(reviews_test.target, predictions))\n",
    "\n",
    "# Train and evaluate logistic regression model\n",
    "lr_model = LogisticRegression(solver='lbfgs').fit(tfidf_vectors, reviews_train.target)\n",
    "predictions = lr_model.predict(tfidf_vectors_test)\n",
    "print(f\"Logistic regression accuracy - num features {max_features}:\", accuracy_score(reviews_test.target, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "* Stop words do not contribute much to the meaning of text in the context of sentiment. TF-IDF vectors very well be dominated by these terms since they are frequent, however should be punished by inverse document frequency.\n",
    "* Stemming: bloated feature space and identical words recognized as different words.\n",
    "* Constraints on DF: very rare words might lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word embeddings**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_kernel",
   "language": "python",
   "name": "jupyter_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
