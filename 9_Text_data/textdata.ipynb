{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (confusion_matrix,precision_score,recall_score,f1_score,\n",
    "    roc_curve,roc_auc_score,precision_recall_curve,accuracy_score,classification_report)\n",
    "from sklearn.decomposition import LatentDirichletAllocation,PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: preprocessing and vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a dataset containing movie reviews from the *Internet Movie Database*. For this, the data first needs to be downloaded from <a href=\"http://ai.stanford.edu/~amaas/data/sentiment/\"> here </a>. Note: this is about 220 Mb.  After uncompressing, the data is contained in a directory `aclImdb` with sub-directories `train` and `test`. In the following, replace the piece of the path that leads to the directory in which you have unpacked the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train=load_files('data/aclImdb/train',categories=['neg','pos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n",
      "b'Everyone plays their part pretty well in this \"little nice movie\". Belushi gets the chance to live part of his life differently, but ends up realizing that what he had was going to be just as good or maybe even better. The movie shows us that we ought to take advantage of the opportunities we have, not the ones we do not or cannot have. If U can get this movie on video for around $10, it\\xc2\\xb4d be an investment!'\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(reviews_train.target_names)\n",
    "revidx = 2\n",
    "print(reviews_train.data[revidx])\n",
    "print(reviews_train.target[revidx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a dictionary (using training data only!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=CountVectorizer(min_df=0.0005, max_df=0.5).fit(reviews_train.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary contains 15862 entries\n",
      "The index of the word 'charming' in the dictionary is 2466\n",
      "The word at index 708 is 'an'\n"
     ]
    }
   ],
   "source": [
    "print(\"The dictionary contains {} entries\".format(len(dictionary.vocabulary_)))\n",
    "wrd='charming'\n",
    "\n",
    "print(\"The index of the word '{}' in the dictionary is {}\".format(wrd,dictionary.vocabulary_[wrd]))\n",
    "widx=708\n",
    "print(\"The word at index {} is '{}'\".format(widx,dictionary.get_feature_names_out()[widx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the underlying preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['everyone', 'plays', 'their', 'part', 'pretty', 'well', 'in', 'this', 'little', 'nice', 'movie', 'belushi', 'gets', 'the', 'chance', 'to', 'live', 'part', 'of', 'his', 'life', 'differently', 'but', 'ends', 'up', 'realizing', 'that', 'what', 'he', 'had', 'was', 'going', 'to', 'be', 'just', 'as', 'good', 'or', 'maybe', 'even', 'better', 'the', 'movie', 'shows', 'us', 'that', 'we', 'ought', 'to', 'take', 'advantage', 'of', 'the', 'opportunities', 'we', 'have', 'not', 'the', 'ones', 'we', 'do', 'not', 'or', 'cannot', 'have', 'if', 'can', 'get', 'this', 'movie', 'on', 'video', 'for', 'around', '10', 'it', 'be', 'an', 'investment']\n"
     ]
    }
   ],
   "source": [
    "analyze = dictionary.build_analyzer()\n",
    "print(analyze(reviews_train.data[revidx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary construction with `CountVectorizer` does not include stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horrendous' 'horrendously' 'horrible' 'horribly' 'horrid']\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.get_feature_names_out()[6951:6956])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specialized tools for tokenization, stemming etc. are provided by the 'nltk' package. We leave this out for now, and go ahead with transforming the data into tf feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of 'reviews_train_tf' is <class 'scipy.sparse._csr.csr_matrix'> with 25000 rows and 15862 columns\n"
     ]
    }
   ],
   "source": [
    "reviews_train_tf=dictionary.transform(reviews_train.data)\n",
    "\n",
    "print(\"The type of 'reviews_train_tf' is {} with {} rows \\\n",
    "and {} columns\".format(type(reviews_train_tf),reviews_train_tf.shape[0],reviews_train_tf.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sparse matrix structure becomes visible, when we print the first 1000 entries of the row for the review at index `revidx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t1\n",
      "  (0, 446)\t1\n",
      "  (0, 708)\t1\n",
      "  (0, 951)\t1\n"
     ]
    }
   ],
   "source": [
    "print(reviews_train_tf[revidx,0:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing 0s are still 'there':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(reviews_train_tf[revidx,405])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also construct a tf-idf representation of the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 951)\t0.11428633904228333\n",
      "  (0, 708)\t0.0627784554562377\n",
      "  (0, 446)\t0.2241656451350434\n",
      "  (0, 7)\t0.10966712876468464\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer_train=TfidfTransformer().fit(reviews_train_tf)\n",
    "reviews_train_tfidf=tfidf_transformer_train.transform(reviews_train_tf)\n",
    "print(reviews_train_tfidf[revidx,0:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the feature vector for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning a Naive Bayes model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb=MultinomialNB().fit(reviews_train_tf,reviews_train.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and transforming the test data. The dictionary used for the test data is the one constructed from the training data! Also the transformation with the idf values is done using the TfidfTransformer constructed from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test=load_files('data/aclImdb/test',categories=['neg','pos'])\n",
    "reviews_test_tf=dictionary.transform(reviews_test.data)\n",
    "reviews_test_tfidf = tfidf_transformer_train.transform(reviews_test_tf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the learned model to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: \n",
      " 0.82968\n",
      "\n",
      "Accuracy on train: \n",
      " 0.87324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_train=mnb.predict(reviews_train_tf)\n",
    "predictions_test=mnb.predict(reviews_test_tf)\n",
    "\n",
    "print(\"Accuracy on test: \\n {}\\n\".format(accuracy_score(reviews_test.target,predictions_test)))\n",
    "print(\"Accuracy on train: \\n {}\\n\".format(accuracy_score(reviews_train.target,predictions_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find out about what words are most indicative of postive/negative reviews, by looking at the parameters of the model.\n",
    "\n",
    "The attribute `feature_log_prob_` returns the log probabilities of the different features (words) under the two classes. By taking the difference for the two classes, we get a measure for how much a word discriminates between the two classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob_diff=mnb.feature_log_prob_[0,:]-mnb.feature_log_prob_[1,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `np.argsort` to obtain the indices of the values in log_prob_diff in increasing order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4636   814  4116  6443  6210 15802 10285 15226  1626  6127  1851  3723\n",
      "  6576 10163  9993 14676 12154  1200  8898  3610  1609  7923 14593  6806\n",
      "  9862 12647  8048 10302  6439 15122]\n"
     ]
    }
   ],
   "source": [
    "sorted_idxs=np.argsort(log_prob_diff)\n",
    "print(sorted_idxs[0:30])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and retrieve the words corresponding to these indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 words most discriminating for positive reviews are:\n",
      "\n",
      "edie\n",
      "antwone\n",
      "din\n",
      "gunga\n",
      "goldsworthy\n",
      "yokai\n",
      "paulie\n",
      "visconti\n",
      "blandings\n",
      "gino\n",
      "brashear\n",
      "deathtrap\n",
      "harilal\n",
      "panahi\n",
      "ossessione\n",
      "tsui\n",
      "sabu\n",
      "aweigh\n",
      "mcintire\n",
      "daisies\n",
      "\n",
      "\n",
      "The 20 words most discriminating for negative reviews are:\n",
      "\n",
      "weisz\n",
      "wayans\n",
      "dyer\n",
      "rosanna\n",
      "dahmer\n",
      "dunaway\n",
      "savini\n",
      "beowulf\n",
      "seagal\n",
      "thunderbirds\n",
      "manos\n",
      "shaq\n",
      "btk\n",
      "saif\n",
      "kareena\n",
      "hobgoblins\n",
      "tashan\n",
      "slater\n",
      "uwe\n",
      "boll\n"
     ]
    }
   ],
   "source": [
    "numfeats=20\n",
    "print(\"The {} words most discriminating for positive reviews are:\\n\".format(numfeats))\n",
    "for i in sorted_idxs[0:numfeats]:\n",
    "    print(dictionary.get_feature_names_out()[i])\n",
    "print(\"\\n\")\n",
    "print(\"The {} words most discriminating for negative reviews are:\\n\".format(numfeats))\n",
    "for i in sorted_idxs[len(sorted_idxs)-numfeats:len(sorted_idxs)]:\n",
    "    print(dictionary.get_feature_names_out()[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that we are overfitting due to very rare words. We can inspect instead words that are a little bit away from the extreme ends of the sorted log_prob_diff vector: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with 'positive rank' between 500 and 520:\n",
      "\n",
      "alienate\n",
      "opposites\n",
      "undercurrent\n",
      "companionship\n",
      "moriarty\n",
      "swordplay\n",
      "demme\n",
      "conductor\n",
      "amicus\n",
      "sergeants\n",
      "trading\n",
      "seamlessly\n",
      "cheryl\n",
      "corinne\n",
      "brilliantly\n",
      "iran\n",
      "shanghai\n",
      "mesmerizing\n",
      "favorites\n",
      "sullivan\n",
      "\n",
      "\n",
      "Words with 'positive rank' between 15342 and 15362:\n",
      "\n",
      "whack\n",
      "humourless\n",
      "sasquatch\n",
      "winston\n",
      "aimlessly\n",
      "whopping\n",
      "plastic\n",
      "horribly\n",
      "horrendous\n",
      "rambo\n",
      "lackluster\n",
      "hulk\n",
      "rehash\n",
      "dafoe\n",
      "bother\n",
      "simpson\n",
      "rubber\n",
      "cringing\n",
      "costs\n",
      "dumb\n"
     ]
    }
   ],
   "source": [
    "numfeats=20\n",
    "offset = 500\n",
    "print(\"Words with 'positive rank' between {} and {}:\\n\".format(offset,offset+numfeats))\n",
    "for i in sorted_idxs[offset:offset+numfeats]:\n",
    "    print(dictionary.get_feature_names_out()[i])\n",
    "print(\"\\n\")\n",
    "print(\"Words with 'positive rank' between {} and {}:\\n\".format(len(sorted_idxs)-numfeats-offset,len(sorted_idxs)-offset))\n",
    "for i in sorted_idxs[len(sorted_idxs)-numfeats-offset:len(sorted_idxs)-offset]:\n",
    "    print(dictionary.get_feature_names_out()[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try a neural network classifier on the tf-idf transformed data next. We use a fairly strong regularization with `alpha=0.5` to compensate for the strong overfitting opportunities in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(alpha=0.5).fit(reviews_train_tfidf,reviews_train.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is runnig (~ 5 minutes ...?), we can take a little break!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test: \n",
      " 0.8824\n",
      "\n",
      "Accuracy on train: \n",
      " 0.9234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_train=mlp.predict(reviews_train_tfidf)\n",
    "predictions_test=mlp.predict(reviews_test_tfidf)\n",
    "\n",
    "\n",
    "print(\"Accuracy on test: \\n {}\\n\".format(accuracy_score(reviews_test.target,predictions_test)))\n",
    "print(\"Accuracy on train: \\n {}\\n\".format(accuracy_score(reviews_train.target,predictions_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the reviews that are evaluated as most positive (negative) by the MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9253 16578  8778 ... 22385 23184 22386]\n"
     ]
    }
   ],
   "source": [
    "most_positive=np.argsort( mlp.predict_proba(reviews_test_tfidf)[:,0] )\n",
    "print(most_positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 3 reviews ranked as most positive are:\n",
      "\n",
      "b\"What a wonderful film, filled with eccentric, unique characters who are wonderfully realized by a great ensemble cast. The director also did a great job keeping the story held together, getting those wonderful performances (on not messing with them) and using music (and what wonderful music it is) to great effect. S. Epatha in the lead role is great. I had always heard what a brilliant stage actor she is, and although I have enjoyed her on Law and Order, this really shows what she can do with a filled out, complex role. Macy Gray is terrific, Mos Def, as usual, wonderful. Lou Gossett, great. Jimmy Smits, terrific, and doesn't try to pull focus because he's a star. A true piece of ensemble acting. <br /><br />Rent it, enjoy it, groove to it, and treasure it. Something special.\"\n",
      "\n",
      "\n",
      "\n",
      "b\"A beautiful, magical, thought-provoking and heart-warming story. Excellent direction, perfect cast, marvellous script, excellent score, beautifully lit...... need I say more?<br /><br />If you love films that not only make you think but also warm your heart (some that spring to mind are 'Contact', 'Field of Dreams' and 'Groundhog Day') then you're sure to love K-PAX.<br /><br />Most highly recommended.\"\n",
      "\n",
      "\n",
      "\n",
      "b'I loved this movie - the actors were wonderful and suited their roles. The story itself was great (and true, the setting was perfect and the message about human response to the war, danger and risk was exceptional. The person who wrote the music score also did the music for Life is Beautiful (another favourite of mine)- his comment was apparently that \"...this was not a like an English movie, it was like an Italian movie.\" I think he\\'s right! Callum Blue is perfect for the part of Eric Newby. I recommend this movie to everyone who wants to watch a story that is true and morally uplifting as well as a beautiful love story.'\n",
      "\n",
      "\n",
      "\n",
      "The 3 reviews ranked as most negative are:\n",
      "\n",
      "b\"This is just the same old crap that is spewed from amateur idiots who have no clue how to make a movie--gee maybe that's why it is a straight-to-video wanna-be movie!<br /><br />I guess it is my fault for actually spending money to see it (one of the worst decisions I have ever made). What a waste. I usually like B movies, some of them are actually quite good--but this is just too ridiculous and stupid to even be funny.<br /><br />The losers that made this junk deserve to be put out of business for wasting everyone's time and money making a movie that obviously doesn't even deserve to be on film! These so-called movie makers have absolutely NO talent!<br /><br />Stupid plot, horrible acting (especially the drag queens--what sicko would actually find that sexy?!), lame writing (if there even was a script--seems like the kinda bull**** someone just made up on the spot)<br /><br />What is stunning about this movie is its utter lack of anything well-done at all.<br /><br />How much attention to detail would it take to insure that every frame of a film would be so far below any reasonable standards? I don't think it would be possible to make such a bad movie intentionally, and it is inconceivable that sheer bad luck could produce such consistently awful results.<br /><br />Anyway, avoid this stink bomb at all costs!!!!!!!!!!!!!!!!\"\n",
      "\n",
      "\n",
      "\n",
      "b\"This movie is pathetic in every way possible. Bad acting, horrible script (was there one?), terrible editing, lousy cinematography, cheap humor. Just plain horrible.<br /><br />I had seen 'The Wishmaster' a couple weeks before this movie and I thought it was a dead-ringer for worst movie of the year. Then, I saw 'The Pest' and suddenly 'The Wishmaster' didn't seem so bad at all.<br /><br />Bad Bad Bad. Excruciatingly bad.\"\n",
      "\n",
      "\n",
      "\n",
      "b'As you can tell from the other comments, this movie is just about the WORST film ever made. Let me see how many different words I can use to describe it: Boring, Unbearable, Laughable, Lousy, Stupid, Horrible.....<br /><br />I could go on with such descriptions but you probably get the point.<br /><br />I would have given this a 0, if possible--bad acting, bad directing, bad production, bad plot.<br /><br />This was made in 2001 and it looks more like 1965. Very low budget, boring plot, horrible acting, really bad special effects, etc...<br /><br />I rarely ever see a Sci-Fi film I absolutely think is this bad. I mean this is pure garbage. It has nothing going for it either. As far as a \"B-movie\" this is the very bottom of the lot.<br /><br />I think I would be more entertained by staring at a blank piece of paper for 90 minutes. Junk like this gives good low-budget \"B\" movies a bad name. This makes Ed Wood movies look good.<br /><br />The thing about watching direct-to-video movies is, just when you think you\\'ve seen the worst, you see something even worse!<br /><br />DJ Perry is a horrible actor and has no individual characteristics that make him stand out.<br /><br />Avoid this waste at all costs! Oh the humanity!'\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numrevs = 3\n",
    "\n",
    "print(\"The {} reviews ranked as most positive are:\\n\".format(numrevs))\n",
    "for i in most_positive[0:numrevs]:\n",
    "    print(reviews_test.data[i])\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "print(\"The {} reviews ranked as most negative are:\\n\".format(numrevs))\n",
    "for i in most_positive[len(most_positive)-numrevs:len(most_positive)]:\n",
    "    print(reviews_test.data[i])\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: install the 'nltk' package https://www.nltk.org/. Now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vugs/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt') #Provides tokenization rules for English\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should work. The package provides customizable methods for tokenization and stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed: \n",
      " b'everyonplaytheirpartprettiwellinthi``littlnicemovi''.belushigetthechanctolivepartofhilifediffer,butenduprealizthatwhathehadwagotobejustasgoodormaybevenbetter.themovishowusthatweoughttotakeadvantagoftheopportunwehave,nottheonewedonotorcannothave.ifucangetthimovionvideoforaround$10,it\\xc2\\xb4dbeaninvest!'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "revidx = 2\n",
    "\n",
    "\n",
    "#print(\"Tokenized: \\n {}\".format(tokens))\n",
    "ps=PorterStemmer()\n",
    "def stem(review):\n",
    "    tokens=word_tokenize(str(review))\n",
    "    stemmed=\"\"\n",
    "    for t in tokens:\n",
    "        stemmed += ps.stem(t)\n",
    "    return stemmed\n",
    "\n",
    "print(\"Stemmed: \\n {}\".format(stem(reviews_train.data[revidx])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise continued**: Create a new (smaller) dictionary from stemmed versions of the reviews. How has the size of the dictionary changed, when you use the same min_df, max_df parameters in the CountVectorizer as before? Redo the NaiveBayes and MLP training with the modified data. Does accuracy improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_corpus = []\n",
    "for i in range(len(reviews_train.data)):\n",
    "    stemmed_corpus.append(stem(reviews_train.data[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=CountVectorizer(min_df=0.0005, max_df=0.5).fit(stemmed_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import a pre-computed 100-dimensional embedding of a vocabulary of 400.000 words. The data can be imported from <a href=\"http://nlp.stanford.edu/data/glove.6B.zip\">here</a> from the <a href=\"https://nlp.stanford.edu/projects/glove/\">Glove homepage</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code copied from https://stackoverflow.com/questions/37793118/load-pretrained-glove-vectors-in-python\n",
    "\n",
    "def loadGloveModel(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(File,'r')\n",
    "    gloveModel = {}\n",
    "    for line in f:\n",
    "        splitLines = line.split()\n",
    "        word = splitLines[0]\n",
    "        wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n",
    "        gloveModel[word] = wordEmbedding\n",
    "    print(len(gloveModel),\" words loaded!\")\n",
    "    return gloveModel\n",
    "\n",
    "gl=loadGloveModel('/home/jaeger/Data/Glove/glove.6B.100d.txt')\n",
    "\n",
    "print(\"The type of the loaded model is {} \\n \".format(type(gl)))\n",
    "\n",
    "print(\"The embedding vector of 'university' is \\n {}\".format(gl['university']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming back to our movie reviews, we create another dictionary from the reviews in the training set. We now set limits that terms included in the dictionary should appear in at least 5% and at most 80% of reviews. These are rather narrow bounds, which are set under the assumption that typical words expressing sentiments will fall into these bounds, while stop words and very many more specific words will be excluded. As it turns out, we create a rather small vocabulary in this manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_small=CountVectorizer(min_df=0.05, max_df=0.8).fit(reviews_train.data)\n",
    "\n",
    "ld=len(dictionary_small.vocabulary_)\n",
    "print(\"Created a dictionary with {} tokens: \\n\".format(ld))\n",
    "for i in range(ld):\n",
    "    print(dictionary_small.get_feature_names()[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new tf feature vectors for the smaller dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_tf=dictionary_small.transform(reviews_train.data)\n",
    "reviews_test_tf=dictionary_small.transform(reviews_test.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need the Glove vector representations of the words in our dictionary. We therefore extract from our 400.000 word original Glove dictionary the relevant ones, and collect them in a matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_glove=np.zeros((ld,100))\n",
    "for i in range(ld):\n",
    "    dict_glove[i,:]=gl[dictionary_small.get_feature_names()[i]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now represent each review by the average of the Glove word vectors of the words in the review (only taking into account those that are in our dictionary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_glove= np.matmul(reviews_train_tf.todense(),dict_glove)\n",
    "for r in range(25000):\n",
    "    reviews_train_glove[r,:]*=(1/np.sum(reviews_train_tf[r,:]))\n",
    "\n",
    "reviews_test_glove= np.matmul(reviews_test_tf.todense(),dict_glove)\n",
    "for r in range(25000):\n",
    "    reviews_test_glove[r,:]*=(1/np.sum(reviews_test_tf[r,:]))\n",
    "\n",
    "\n",
    "print(\"glove feature matrix for training reviews has dimensions {}\".format(reviews_train_glove.shape))\n",
    "print(\"glove feature matrix for testing reviews has dimensions {}\".format(reviews_test_glove.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train classifiers for predicting the sentiment of a review from either the term-frequency features, or the GLove average embedding vectors. Remember that the tf-vectors are now over a smaller dictionary, so the accuracy results we get can be expected to be lower than in Part 1. The true class labels are retrieved by `reviews_train.target` and `reviews_test.target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifyer = MLPClassifier((10))\n",
    "#classifyer =  LogisticRegression(solver='lbfgs')\n",
    "train={}\n",
    "train[\"tf\"]=reviews_train_tf\n",
    "train[\"glove\"]=reviews_train_glove\n",
    "test={}\n",
    "test[\"tf\"]=reviews_test_tf\n",
    "test[\"glove\"]=reviews_test_glove\n",
    "\n",
    "for features in (\"tf\",\"glove\"):\n",
    "    print(\"Training with \" + features + \"  features \\n\")\n",
    "    classifyer.fit(train[features],reviews_train.target)\n",
    "    pred_train=classifyer.predict(train[features])\n",
    "    pred_test=classifyer.predict(test[features])\n",
    "    print(\"Evaluation on training data: \\n\")\n",
    "    print(\"Confusion matrix: \\n {}\".format(confusion_matrix(pred_train,reviews_train.target)))\n",
    "    print(\"Accuracy: \\n {} \\n\".format(accuracy_score(pred_train,reviews_train.target)))\n",
    "    print(\"Evaluation on test data: \\n\")\n",
    "    print(\"Confusion matrix: \\n {}\".format(confusion_matrix(pred_test,reviews_test.target)))\n",
    "    print(\"Accuracy: \\n {}\\n\\n\".format(accuracy_score(pred_test,reviews_test.target)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent on the random initializations, some learning runs here may end with an warning message that the optimization has not converged after the maximum number of iterations. In that case one can re-run, increase the maximum number of iterations, or live with the results that one has obtained from the not fully converged runs...\n",
    "\n",
    "In these initial experiments, we are likely to see results where the Glove features lead to a slightly lower accuracy on the test data than the TF features. One could explore this further in many different dimensions: modify the underlying vocabulary, create more sophisticated Glove-based features than simple averages, consider other classification models, ...\n",
    "\n",
    "Finally, we can visualize the Glove embeddings of the words in our dictionary by plotting a 2-dimensional projection computed by principal component analysis (PCA): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=2)\n",
    "glove_pca=pca.fit_transform(dict_glove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "plt.scatter(glove_pca[:,0],glove_pca[:,1],)\n",
    "\n",
    "for i in range(ld):\n",
    "    plt.annotate(dictionary_small.get_feature_names()[i],(glove_pca[i,0],glove_pca[i,1]),fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This picture can partly explain why our sentiment analysis task remains hard with Glove features:  relevant descriptive adjectives 'stupid', 'awful', 'wonderful', 'funny', 'boring', ... are clustered in the same area of the latent space. It would be more helpful, if the positive adjectives were well separated from the negative adjectives (bearing in mind, that this 2-d projection does not tell the whole story!). \n",
    "\n",
    "An interesting detail can be seen on the top of the plot: from this embedding, we would obtain for the analogical query <i>'films' is to 'film' what ??? is to 'movie'</i> the answer ???='movies'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since LDA requires some rather time-consuming computations, we again create a dictionary with a suitable size ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=CountVectorizer(min_df=0.01, max_df=0.15).fit(reviews_train.data)\n",
    "print(\"The dictionary contains {} entries\".format(len(dictionary.vocabulary_)))\n",
    "reviews_train_tf=dictionary.transform(reviews_train.data)\n",
    "reviews_train_tfidf=TfidfTransformer().fit_transform(reviews_train_tf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit an LDA model with `ntopics` latent topics. The LDA learner has a parameter `max_iter` that determines how many iterations over the whole dataset are performed. A *perplexity* score measures how well the learned model explains/fits the data. When time permits, one can see how the perplexity score improves when one allows more iterations in the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntopics=20\n",
    "\n",
    "#maxiters = np.array([5,10])\n",
    "maxiters = 5\n",
    "\n",
    "for m in range(maxiters):\n",
    "    start=time.time()\n",
    "    lda = LatentDirichletAllocation(n_components=ntopics,learning_method='online',max_iter=m).fit(reviews_train_tf)\n",
    "    end=time.time()\n",
    "    print(\"Time: {}s\".format(end-start))\n",
    "    print(\"Iterations performed: {}\".format(lda.n_iter_))\n",
    "    print(\"Perplexity score: {}\".format(lda.perplexity(reviews_train_vec)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `components_` contains the word probabilities for the latent topics (not strictly probabilities, because they do not sum to 1 over all words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda.components_.shape)\n",
    "comp=0\n",
    "f=30\n",
    "print(\"The first {} words have the following 'probabilities' in component {}:\\n {}\\n\"\\\n",
    "      .format(f,comp,lda.components_[comp,0:f]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next investigate which words have the highest probabilities under the different topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widx_ranks=np.argsort(lda.components_,axis=1)\n",
    "\n",
    "numwords=20\n",
    "for i in np.arange(ntopics):\n",
    "    print(\"Topic {}\\n\".format(i))\n",
    "    for j in np.arange(numwords):\n",
    "        print(dictionary.get_feature_names()[widx_ranks[i,len(dictionary.vocabulary_)-j-1]])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we investigate the topic distributions assigned to the different reviews. These have first to be computed using the `transform` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicvecs = lda.transform(reviews_train_tf)\n",
    "\n",
    "print(topicvecs.shape)\n",
    "print(topicvecs[0:3,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can look which reviews are most strongly connected to any specific topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "toprevs_by_topic=np.argsort(topicvecs,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index of the topic we want to investigate\n",
    "topicno=7\n",
    "# The number of reviews most highly associated with the topic that we want to see\n",
    "norevs=4\n",
    "\n",
    "l=len(toprevs_by_topic)-1\n",
    "\n",
    "for i in np.arange(norevs):\n",
    "    print(reviews_train.data[toprevs_by_topic[l-i,topicno]])\n",
    "\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Try different classifiers (MLP, SVM) for classifying the reviews based on their topic vectors. <b>\n",
    "    \n",
    "**Exercise (self study):** Fix a dimensionality d for vector representations, e.g. d=50, d=100, d=1000. Construct different representations of the reviews as d-dimensional vectors: <b>\n",
    "    \n",
    "<ul>\n",
    "    <li>tf-idf vectors for a dictionary of size d</li>\n",
    "     <li>mean word embedding vectors from d-dimensional word vectors (the GloVe homepage provides embeddings of different dimensions</li>\n",
    "    <li>LDA topic vectors for d topics </li>\n",
    " </ul>\n",
    "    \n",
    "Train and evaluate different classifiers on these different representations. What are the relevant tuning possibilities you can use to optimize the performance of each type of representation? Which approach gives you the best performance for the given \"budget\" of d dimensions for representation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
